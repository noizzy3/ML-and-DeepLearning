tf.Variable(tf.random_uniform([1],-1.0,1.0)) // 1 dimension variable b/w -1 to +1
tf.Variable(np.zeros((2,3)))
tf.zeros([2,3])

loss = tf.reduce_mean(tf.square(y - y_))
optimiser = tf.train.GradientDescentOptimizer(0.5)
train = optimiser.minimize(loss)

tf.constant([[3, 3]]) //2 cols 1 row
tf.constant([[3], [3]]) //1 col 2 rows

state = tf.Variable(0,name="counter")
print(state.name)
// output:- counter:0

tf.assign(x, y) //assigns the value of y to x

........tf.expand_dims()
#     't' is a tensor of shape [2]
#shape(expand_dims(t, 0)) ==> [1, 2]
#shape(expand_dims(t, 1)) ==> [2, 1]
#shape(expand_dims(t, -1)) ==> [2, 1] "-1 signifies that one extra dimension is added in the end"

## 't2' is a tensor of shape [2, 3, 5]
#shape(expand_dims(t2, 0)) ==> [1, 2, 3, 5]
#shape(expand_dims(t2, 2)) ==> [2, 3, 1, 5]
#shape(expand_dims(t2, 3)) ==> [2, 3, 5, 1]

........tf.squeeze()
#Given a tensor input, this operation returns a tensor of the same type with all dimensions of size 1 removed. If you don't want to remove all #size 1 dimensions, you can remove specific size 1 dimensions by specifying axis.

#For example:

## 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
#shape(squeeze(t)) ==> [2, 3]
#Or, to remove specific size 1 dimensions:

## 't' is a tensor of shape [1, 2, 1, 3, 1, 1]
#shape(squeeze(t, [2, 4])) ==> [1, 2, 3, 1]


cross entropy is a loss function: to calculate the error in the calculated values	
# 'tensor' is [[1, 2, 3], [4, 5, 6]]
tf.ones_like(tensor) ==> [[1, 1, 1], [1, 1, 1]]
init = tf.global_variables_initializer()


y = np.concatenate((trY, teY), axis=0) #row wise
y = np.concatenate((trY, teY), axis=1) #column-wise